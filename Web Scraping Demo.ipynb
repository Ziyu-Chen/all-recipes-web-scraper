{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        print(soup_obj)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the name\n",
    "        name = soup_obj.find('h1', id='recipe-main-content')\n",
    "        if name:\n",
    "            name = get_text(name)\n",
    "        print(name)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the category information\n",
    "        categories = soup_obj.find_all('span', 'toggle-similar__title')\n",
    "        if categories:\n",
    "            categories = list(map(get_text, categories))\n",
    "        print(categories)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the description\n",
    "        description = soup_obj.find('div', 'submitter__description')\n",
    "        if description:\n",
    "            description = get_text(description)\n",
    "        print(description)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the author\n",
    "        author = soup_obj.find('span', 'submitter__name')\n",
    "        if author:\n",
    "            author = get_text(author)\n",
    "        print(author)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the star rating \n",
    "        rating = soup_obj.find(\"div\", \"rating-stars\")\n",
    "        if rating:\n",
    "            rating = rating.attrs['data-ratingstars']\n",
    "        print(rating)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def is_ingredient(item):\n",
    "    if (item == 'Add all ingredients to list'): \n",
    "        return False\n",
    "    if (item.endswith(':')):\n",
    "        return False\n",
    "    if (len(item) == 0):\n",
    "        return False\n",
    "    return True\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the list of ingredients\n",
    "        ingredients = map(get_text, soup_obj.find_all('li', 'checkList__line'))\n",
    "        if ingredients:\n",
    "            ingredients = list(filter(is_ingredient ,ingredients))\n",
    "        print(ingredients)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the prep time / cook time / total time\n",
    "        time = soup_obj.find('ul', 'prepTime')\n",
    "        \n",
    "        prep_time = time.find('time', attrs={\"itemprop\": \"prepTime\"})\n",
    "        if prep_time:\n",
    "            prep_time = prep_time.text\n",
    "        print(prep_time)\n",
    "            \n",
    "        cook_time = time.find('time', attrs={\"itemprop\": \"cookTime\"})\n",
    "        if cook_time:\n",
    "            cook_time = cook_time.text\n",
    "        print(cook_time)\n",
    "            \n",
    "        total_time = time.find('time', attrs={\"itemprop\": \"totalTime\"})\n",
    "        if total_time:\n",
    "            total_time = total_time.text\n",
    "        print(total_time)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def minute_converter(string):\n",
    "    array = string.split()\n",
    "    #print(string)\n",
    "    minutes = 0\n",
    "    for i in range(len(array))[::2]:\n",
    "        if (array[i+1] == 'h'):\n",
    "            minutes += int(array[i]) * 60\n",
    "        if (array[i+1] == 'm'):\n",
    "            minutes += int(array[i])\n",
    "    return minutes\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the prep time / cook time / total time\n",
    "        time = soup_obj.find('ul', 'prepTime')\n",
    "        \n",
    "        prep_time = time.find('time', attrs={\"itemprop\": \"prepTime\"})\n",
    "        if prep_time:\n",
    "            prep_time = minute_converter(prep_time.text)\n",
    "        print(prep_time)\n",
    "            \n",
    "        cook_time = time.find('time', attrs={\"itemprop\": \"cookTime\"})\n",
    "        if cook_time:\n",
    "            cook_time = minute_converter(cook_time.text)\n",
    "        print(cook_time)\n",
    "            \n",
    "        total_time = time.find('time', attrs={\"itemprop\": \"totalTime\"})\n",
    "        if total_time:\n",
    "            total_time = minute_converter(total_time.text)\n",
    "        print(total_time)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def is_direction(item):\n",
    "    if (len(item) == 0):\n",
    "        return False\n",
    "    return True\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the directions\n",
    "        directions = soup_obj.find_all('span', 'recipe-directions__list--item')\n",
    "        if directions:\n",
    "            directions = list(filter(is_direction, (map(get_text, directions))))\n",
    "        print(directions)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the nutrition facts\n",
    "        nutritions = soup_obj.find('div', 'nutrition-summary-facts')\n",
    "        \n",
    "        calories = nutritions.find('span', attrs={\"itemprop\": \"calories\"})\n",
    "        if calories:\n",
    "            calories = re.search('\\d+',calories.text).group(0)\n",
    "        print(calories)\n",
    "            \n",
    "        fat = nutritions.find('span', attrs={\"itemprop\": \"fatContent\"})\n",
    "        if fat:\n",
    "            fat = get_text(fat)\n",
    "        print(fat)\n",
    "            \n",
    "        carbohydrates = nutritions.find('span', attrs={\"itemprop\": \"carbohydrateContent\"})\n",
    "        if carbohydrates:\n",
    "            carbohydrates = get_text(carbohydrates)\n",
    "        print(carbohydrates)\n",
    "            \n",
    "        protein = nutritions.find('span', attrs={\"itemprop\": \"proteinContent\"})\n",
    "        if protein:\n",
    "            protein = get_text(protein)\n",
    "        print(protein)\n",
    "        \n",
    "        cholesterol = nutritions.find('span', attrs={\"itemprop\": \"cholesterolContent\"})\n",
    "        if cholesterol:\n",
    "            cholesterol = get_text(cholesterol)\n",
    "        print(cholesterol)\n",
    "            \n",
    "        sodium = nutritions.find('span', attrs={\"itemprop\": \"sodiumContent\"})\n",
    "        if sodium:\n",
    "            sodium = get_text(sodium)\n",
    "        print(sodium)\n",
    "    else:\n",
    "        print(\"Can't access \" + url)\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def is_ingredient(item):\n",
    "    if (item == 'Add all ingredients to list'): \n",
    "        return False\n",
    "    if (item.endswith(':')):\n",
    "        return False\n",
    "    if (len(item) == 0):\n",
    "        return False\n",
    "    return True\n",
    "def is_direction(item):\n",
    "    if (len(item) == 0):\n",
    "        return False\n",
    "    return True\n",
    "def minute_converter(string):\n",
    "    array = string.split()\n",
    "    #print(string)\n",
    "    minutes = 0\n",
    "    for i in range(len(array))[::2]:\n",
    "        if (array[i+1] == 'h'):\n",
    "            minutes += int(array[i]) * 60\n",
    "        if (array[i+1] == 'm'):\n",
    "            minutes += int(array[i])\n",
    "    return minutes\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the category information\n",
    "        categories = soup_obj.find('ol', 'breadcrumbs').find_all('span', 'toggle-similar__title')\n",
    "        if categories:\n",
    "            categories = list(map(get_text, categories))[2:]\n",
    "        \n",
    "        # Get the name\n",
    "        name = soup_obj.find('h1', id='recipe-main-content')\n",
    "        if name:\n",
    "            name = name.text.strip()\n",
    "        \n",
    "        # Get the description\n",
    "        description = soup_obj.find('div', 'submitter__description')\n",
    "        if description:\n",
    "            description = description.text.strip()\n",
    "            \n",
    "        # Get the author\n",
    "        author = soup_obj.find('span', 'submitter__name')\n",
    "        if author:\n",
    "            author = author.text\n",
    "        \n",
    "        # Get the star rating \n",
    "        rating = soup_obj.find(\"div\", \"rating-stars\")\n",
    "        if rating:\n",
    "            rating = rating.attrs['data-ratingstars']\n",
    "        \n",
    "        # Get the list of ingredients\n",
    "        ingredients = map(get_text, soup_obj.find_all('li', 'checkList__line'))\n",
    "        if ingredients:\n",
    "            ingredients = list(filter(is_ingredient ,ingredients))\n",
    "        \n",
    "        # Get the prep time / cook time / total time\n",
    "        time = soup_obj.find('ul', 'prepTime')\n",
    "        \n",
    "        prep_time = time.find('time', attrs={\"itemprop\": \"prepTime\"})\n",
    "        if prep_time:\n",
    "            prep_time = minute_converter(prep_time.text)\n",
    "            \n",
    "        cook_time = time.find('time', attrs={\"itemprop\": \"cookTime\"})\n",
    "        if cook_time:\n",
    "            cook_time = minute_converter(cook_time.text)\n",
    "            \n",
    "        total_time = time.find('time', attrs={\"itemprop\": \"totalTime\"})\n",
    "        if total_time:\n",
    "            total_time = minute_converter(total_time.text)\n",
    "        \n",
    "        # Get the directions\n",
    "        directions = soup_obj.find_all('span', 'recipe-directions__list--item')\n",
    "        if directions:\n",
    "            directions = list(filter(is_direction, (map(get_text, directions))))\n",
    "\n",
    "        # Get the nutrition facts\n",
    "        nutritions = soup_obj.find('div', 'nutrition-summary-facts')\n",
    "        \n",
    "        calories = nutritions.find('span', attrs={\"itemprop\": \"calories\"})\n",
    "        if calories:\n",
    "            calories = re.search('\\d+',calories.text).group(0)\n",
    "            \n",
    "        fat = nutritions.find('span', attrs={\"itemprop\": \"fatContent\"})\n",
    "        if fat:\n",
    "            fat = get_text(fat)\n",
    "            \n",
    "        carbohydrates = nutritions.find('span', attrs={\"itemprop\": \"carbohydrateContent\"})\n",
    "        if carbohydrates:\n",
    "            carbohydrates = get_text(carbohydrates)\n",
    "            \n",
    "        protein = nutritions.find('span', attrs={\"itemprop\": \"proteinContent\"})\n",
    "        if protein:\n",
    "            protein = get_text(protein)\n",
    "        \n",
    "        cholesterol = nutritions.find('span', attrs={\"itemprop\": \"cholesterolContent\"})\n",
    "        if cholesterol:\n",
    "            cholesterol = get_text(cholesterol)\n",
    "            \n",
    "        sodium = nutritions.find('span', attrs={\"itemprop\": \"sodiumContent\"})\n",
    "        if sodium:\n",
    "            sodium = get_text(sodium)\n",
    "        \n",
    "        recipe = {\n",
    "            'name': name,\n",
    "            'description': description,\n",
    "            'categories': categories,\n",
    "            'rating': rating,\n",
    "            'ingredients': ingredients,\n",
    "            'prep_time': prep_time,\n",
    "            'cook_time': cook_time,\n",
    "            'total_time': total_time,\n",
    "            'directions': directions,\n",
    "            'calories': calories,\n",
    "            'fat': fat,\n",
    "            'carbohydrates': carbohydrates,\n",
    "            'protein': protein,\n",
    "            'cholesterol': cholesterol,\n",
    "            'sodium': sodium,\n",
    "            'author': author,\n",
    "            'source': url\n",
    "        }\n",
    "        \n",
    "        print(recipe)\n",
    "        \n",
    "    else:\n",
    "        print(\"Can't access this page\")\n",
    "info_collector('https://www.allrecipes.com/recipe/231306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(element):\n",
    "    return element.text.replace('\\n', '').strip()\n",
    "def is_ingredient(item):\n",
    "    if (item == 'Add all ingredients to list'): \n",
    "        return False\n",
    "    if (item.endswith(':')):\n",
    "        return False\n",
    "    if (len(item) == 0):\n",
    "        return False\n",
    "    return True\n",
    "def is_direction(item):\n",
    "    if (len(item) == 0):\n",
    "        return False\n",
    "    return True\n",
    "def minute_converter(string):\n",
    "    array = string.split()\n",
    "    #print(string)\n",
    "    minutes = 0\n",
    "    for i in range(len(array))[::2]:\n",
    "        if (array[i+1] == 'h'):\n",
    "            minutes += int(array[i]) * 60\n",
    "        if (array[i+1] == 'm'):\n",
    "            minutes += int(array[i])\n",
    "    return minutes\n",
    "def info_collector(url):\n",
    "    response = requests.get(url, headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}) # Requesting the html page\n",
    "    if response.status_code == 200:\n",
    "        soup_obj = bs4.BeautifulSoup(response.text,'lxml')\n",
    "        soup_obj.prettify()\n",
    "        \n",
    "        # Get the category information\n",
    "        categories = soup_obj.find('ol', 'breadcrumbs').find_all('span', 'toggle-similar__title')\n",
    "        if categories:\n",
    "            categories = list(map(get_text, categories))[2:]\n",
    "        \n",
    "        # Get the name\n",
    "        name = soup_obj.find('h1', id='recipe-main-content')\n",
    "        if name:\n",
    "            name = name.text.strip()\n",
    "        \n",
    "        # Get the description\n",
    "        description = soup_obj.find('div', 'submitter__description')\n",
    "        if description:\n",
    "            description = description.text.strip()\n",
    "            \n",
    "        # Get the author\n",
    "        author = soup_obj.find('span', 'submitter__name')\n",
    "        if author:\n",
    "            author = author.text\n",
    "        \n",
    "        # Get the star rating \n",
    "        rating = soup_obj.find(\"div\", \"rating-stars\")\n",
    "        if rating:\n",
    "            rating = rating.attrs['data-ratingstars']\n",
    "        \n",
    "        # Get the list of ingredients\n",
    "        ingredients = map(get_text, soup_obj.find_all('li', 'checkList__line'))\n",
    "        if ingredients:\n",
    "            ingredients = list(filter(is_ingredient ,ingredients))\n",
    "        \n",
    "        # Get the prep time / cook time / total time\n",
    "        time = soup_obj.find('ul', 'prepTime')\n",
    "        \n",
    "        prep_time = time.find('time', attrs={\"itemprop\": \"prepTime\"})\n",
    "        if prep_time:\n",
    "            prep_time = minute_converter(prep_time.text)\n",
    "            \n",
    "        cook_time = time.find('time', attrs={\"itemprop\": \"cookTime\"})\n",
    "        if cook_time:\n",
    "            cook_time = minute_converter(cook_time.text)\n",
    "            \n",
    "        total_time = time.find('time', attrs={\"itemprop\": \"totalTime\"})\n",
    "        if total_time:\n",
    "            total_time = minute_converter(total_time.text)\n",
    "        \n",
    "        # Get the directions\n",
    "        directions = soup_obj.find_all('span', 'recipe-directions__list--item')\n",
    "        if directions:\n",
    "            directions = list(filter(is_direction, (map(get_text, directions))))\n",
    "\n",
    "        # Get the nutrition facts\n",
    "        nutritions = soup_obj.find('div', 'nutrition-summary-facts')\n",
    "        \n",
    "        calories = nutritions.find('span', attrs={\"itemprop\": \"calories\"})\n",
    "        if calories:\n",
    "            calories = re.search('\\d+',calories.text).group(0)\n",
    "            \n",
    "        fat = nutritions.find('span', attrs={\"itemprop\": \"fatContent\"})\n",
    "        if fat:\n",
    "            fat = get_text(fat)\n",
    "            \n",
    "        carbohydrates = nutritions.find('span', attrs={\"itemprop\": \"carbohydrateContent\"})\n",
    "        if carbohydrates:\n",
    "            carbohydrates = get_text(carbohydrates)\n",
    "            \n",
    "        protein = nutritions.find('span', attrs={\"itemprop\": \"proteinContent\"})\n",
    "        if protein:\n",
    "            protein = get_text(protein)\n",
    "        \n",
    "        cholesterol = nutritions.find('span', attrs={\"itemprop\": \"cholesterolContent\"})\n",
    "        if cholesterol:\n",
    "            cholesterol = get_text(cholesterol)\n",
    "            \n",
    "        sodium = nutritions.find('span', attrs={\"itemprop\": \"sodiumContent\"})\n",
    "        if sodium:\n",
    "            sodium = get_text(sodium)\n",
    "        \n",
    "        recipe = {\n",
    "            'name': name,\n",
    "            'description': description,\n",
    "            'categories': categories,\n",
    "            'rating': rating,\n",
    "            'ingredients': ingredients,\n",
    "            'prep_time': prep_time,\n",
    "            'cook_time': cook_time,\n",
    "            'total_time': total_time,\n",
    "            'directions': directions,\n",
    "            'calories': calories,\n",
    "            'fat': fat,\n",
    "            'carbohydrates': carbohydrates,\n",
    "            'protein': protein,\n",
    "            'cholesterol': cholesterol,\n",
    "            'sodium': sodium,\n",
    "            'author': author,\n",
    "            'source': url\n",
    "        }\n",
    "        \n",
    "        recipes.append(recipe)\n",
    "        \n",
    "    else:\n",
    "        print(\"Can't access this page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = []\n",
    "for i in range(9500, 275979):\n",
    "    try:\n",
    "        info_collector('https://www.allrecipes.com/recipe/%d' % i)\n",
    "        print(\"Finished getting recipe No.%d\" % i)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ZiyuChen/assignment/recipes.json', 'w') as outfile:\n",
    "    outfile.write(json.dumps(recipes[:3713], indent=4, sort_keys=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
